.. _generative_ai_for_everyone:

======================================
吴恩达《Generative AI for Everyone》
======================================

和 :ref:`ai_for_everyone` 相似， `吴恩达最新《面向每个人的生成式AI》Generative AI for Everyone <https://www.bilibili.com/video/BV11G411X7nZ/>`_ 是一个入门级非技术型视频讲座，对于普通人了解生成式AI基本原理、破除过度神话AI有很大帮助。本文是我观看摘要，仅供参考。建议观看原视频!

生成式AI的崛起
====================

Generative AI，即生成式AI是2022年11月开始引起主流关注的人工智能技术，起因是OpenAI发布了 ``ChatGPT`` ，令人惊叹的拟人化对答，几乎无所不知的知识和"推理"似乎远超普通人的认知。

.. note::

   生成式AI对我们生活和工作的影响，特别是编程、文稿、艺术类，已经显现出端倪。就像一个超级无敌的搜索引擎的自动汇编者，普通人的知识和技能储备是无法和人类历史上所有知识的积累相比较的。

   目前值得思考的是，生成式AI限于原理仅仅是人类历史知识的 ``概率性浓缩`` ，它自身是没有理解能力和主动性的。所以一个良好训练的人类依然能够以自己的理性和感情，指引生成式AI执行和review结果进行调整。

**生成式AI为世界带来了对生产力巨大提升的期待，也带来了自动化导致失业的忧虑**

生成式AI的定义
================

生成式AI指能够产生高质量内容，特别是文本、图像、音频、视频的人工智能系统: 根据用户输入的提示词(prompt)生成内容

.. note::

   **我的理解** :

   生成式AI对软件开发工作有很深刻的影响，相当于中低级别的开发人员(自动生成常规重复性代码，但是需要人类把关)，所以有可能使用者必须达到非常高的层次才能真正理解和掌握编程类生成式AI。而此时，中低端开发人员已经没有工作可干了，除非你更加磨练自己的技能上升到高级开发者的水平。

生成式AI的工作原理
=======================

- 当前主要的AI技术:

  - 监督学习(标记)
  - 生成式AI: 目前生成式AI主要通过监督学习来构建
  - 无监督学习
  - 强化学习

.. figure:: ../../_static/machine_learning/basic/ai_tools.png

   AI技术

监督学习
------------

.. figure:: ../../_static/machine_learning/basic/supervised_learning_examples.png

   监督学习的应用案例

大规模监督学习为现代生成式AI奠定了基础(2010-2020年):

- 发现在非常快速、强大且拥有大量内存的计算机上训练AI大模型，当输入越来越多的数据时，就会不断地变得越来越好

  - 这个特性和AI小模型不同，AI小模型不会随着输入数据增加而不断提升性能(在一定数据输入后不再提升性能)

- 使用大语言模型(Large Language Models, LLMs)生成文本

  - 本质是通过监督学习(A->B)来预测下一个单词

.. figure:: ../../_static/machine_learning/basic/llms_work.png

   通过监督学习构建LLM，预测一句语句中每个单词的下一个单词   

大语言模型
=============

大语言模型提供了寻找信息的新方式:

- 大语言模型能够直接回答问题(海量人类知识数据训练)
- 大语言模型会编造事情，而且看起来很权威和自行，这就是大语言模型的幻觉(概率原理)，如果对真实性有高要求一定要有专业能力辨析真伪
- 大语言模型可能需要多轮对话来引导模型给住正确答案(我感觉是通过不断提醒LLM实际上提示词增加了正确答案的概率，因为提示词和正确答案之间的概率相关性更强)
- 大语言模型有时可以作为思维伙伴来帮助你思考问题(实际上是历史上海量的人类知识根据你的提示词被概率提取出来，从而触发了你自己的目标灵感)

  - 可以将你的提纲或文章重写(润色)，因为你的提纲和文章相当于映射到人类文明历史中的知识的概率提示词，大语言模型将以全人类的知识文明来扩展你有限的文笔能力
  - 但是，反过来也限制了你的扩展和想像能力，因为你的大脑将退化掉迭代能力(所以我觉得不应该照抄，而是想办法和大语言模型对话，启发自己，由自己来重新而不是由大语言模型代笔)

生成式AI的使用案例
=====================

AI对很多任务都有用，就像电力驱动了不同的设备(无所不在)


- 写作

  - 提供一些词汇(想法)，LLM就能够像头脑风暴一样提供创意建议(本质上也人类积累的知识概率提取,普通人不可能看过所有人类的知识，但是LLM训练过程会扫描所有知识)
  - 回答企业相关知识问题
  - 提示词越详细越贴合需求，则得到的生成内容越专业越精准

- 翻译

  - 大语言模型翻译，特别是对于在互联网上有大量文本的语言，则翻译越精准；反之，对于低资源语言(互联网上该语言的文本较少)的翻译往往较差

- 阅读

  - 代替人类阅读大数据量的文章，并提取关键信息浓缩成概要
  - 校对人类撰写的文档分析语法和拼写错误并提供修正
  - 语音信息转录文本以后可以通过LLM进行摘要，方便管理者快速了解和评估
  - 阅读邮件判断分类，将客户邮件路由到合适处理的部门
  - 点评网站根据用户点评进行用户情感分析(正向评论或负面评论)

- 聊天

  - 构建在线(专业)聊天机器人: 旅游规划、职业规划指导、烹饪建议
  - 机器人调用公司的各种软件接口来执行特定任务: 外卖、IT管理的特定任务
  - 客户服务中的chatboots:

    - 混合人工和bots的对话服务(human in the loop)，以降低LLM生成错误导致异常概率
    - 使用bot triages for humans模式，自动分流简单任务给bot处理，复杂任务给人类处理，以提高服务效率
    - 通过bots，客服能够并发服务更多的客户

生成式AI(LLMs)的缺陷
================================

- LLMs是通过训练获得推理能力，所以它的训练集截止时间决定了它的能力范围或者说它的信息来源(知识截止点, knowledge cutoff)。
- 幻觉: 也就是LLM有时候会编造信息(例如要求提供三句莎士比亚写的有关碧昂丝的名言，显然这是不可能的事，但是LLM会编造; 例如LLM会编造虚假的法庭判例)
- 输入(和输出)长度有限: 大多数LLMs不能接受超过数千的提示词，并且用户提交的上下文总量是有限的(上下文总量其实是驶入和输出大小的总量)
- 目前LLMs还无法很好地处理结构化数据(监督学习是处理结构化数据较好的技术)；相反，LLs擅长处理非结构化数据(文本、图像、音频、视频)
- 生成式AI还容易产生偏见，甚至输出有毒或有害言论(因为训练文本取自互联网，而互联网上文本可能反映社会中存在的偏见)

提示词(prompt)技巧
====================

- 提示词要详细和具体

  - 提供足够的上下文或足够的背景信息，明确你想要得到的结果

- 提示词要引导模型思考它的答案

- 实验和迭代

  - 最初可能不是最好，通过尝试调整使得输出更接近想要的答案
  - 以简单的提示词快速开始，并根据输出思考为何没有达到想要的目标，然后完善提示词以澄清指令

- 需要考虑提示词的机密性要求

- 并考虑是否信任LLM输出(double check)

.. figure:: ../../_static/machine_learning/basic/llm_prompt.png

   LLM提示词需要不断迭代

图像生成
===============

能够生成文本或图像的多模态大模型:

- 图像生成主要通过扩散模型的方法来完成: 扩散模型从大量的图形中学习(扩散模型是监督学习)

  - 首先向图像添加噪音，使得图像变得嘈杂，最终得到一个看起来像纯噪声的图片(完全碎片看不出原图)
  - 以上述方式不断处理海量图片让系统学习
  - 生成图片是反向操作，将噪声图片反向去除噪声，直到形成清晰的图像
  - 由于训练时，用于训练的图片是有标签，并添加噪声形成完全噪声图片；当生成图片输入提示词时，会反向执行将最终噪声图片去噪

.. figure:: ../../_static/machine_learning/basic/prompt_to_image.png

   LLM提示词反向将图片去除噪音

Generative AI的生命周期
============================

构建Generative AI是一个高度实验性的过程，需要不断尝试并修正错误:

- 提示词
- 检索增强生成(Retrieval augmented generation, RAG)

  - RAG为大语言模型访问外部数据提供了能力

- 微调模型(Fine-tune models)

  - 将大模型修改成适合你的任务

- 预训练模型(Pretrain models)

  - 从头开始训练LLM(Train LLM from scratch)

Generative AI的成本估算
===========================

token可能是一个单词，也可能是一个单词的子集(常见单词可能每个单词是一个token，而不常见的单词可能会被拆分成多个token)，总体平均来说 **1个token** 大约是 ``3/4个单词``

检索增强生成(RAG, Retrieval Augmented Generation)
====================================================

RAG(检索增强生成)技术:

- RAG首先会查看可能包含答案的文档集合
- 将检索到的文档整合到更新的提示中(注意大语言模型对输入长度有限制，所以通常只会把文档中与问题最相关的部分提取并放到提示中)
- 根据这更为丰富的提示LLM，最后希望LLM会给我们一个深思熟虑的答案

现在大语言模型能够根据用户上传的pdf文档，让用户提问来结合上传的文档进行答复，就是RAG技术的案例。

RAG相当于一个推理引擎来帮助用户处理信息，这拓展了常规的LLM仅根据训练数据(llm见到过的互联网资料)提供记忆和查询(类似数据库)而是拓展了使用者的头脑，快速完成提炼总结以及实现类似头脑风暴的功能。

微调(Fine-tuning)
======================

如果有更大的上下文，超出了语言模型输入长度或输入上下文窗口的长度，微调(fine-tuning)技术提供了让语言模型吸收信息的方法，并且能让语言模型以某种特定风格输出文本。但是fine-tuning比RAG实现要困难。

大语言模型训练使用了海量的互联网资料，但是我们会希望大模型以我们期望的方式运行，例如希望具有积极乐观的态度，就可以使用微调技术。通过创建一个额外的数据集(给定训练目标的类型的文本)。这个微调数据集比原先大语言预训练的数据集要小很多规模，但是只要使用适当规模的微调数据集，就能够改变语言模型的输出，获得诸如积极乐观的输出文本。

微调模型的常见方案:

- 微调大模型用某种摘要风格完成，此时通过人类专家编写的一些摘要或小说，就能将通用大模型的摘要风格按照需要进行调整，模仿特定的写作或说话风格。
- 让模型能够完成医学技术诊断: 专业术语以及诊断书写，或者反过来对诊断书进行分析说明
- 法律文件: 微调技术能够将专业法律文件转换成常人能够理解阅读的文档
- 金融文件: 在大量金融文件上训练大语言模型，再通过微调能够更好地解析形成良好的金融知识体系，使得其处理文件更优

微调的另一个优势是能够以较小的模型来运行，降低运行成本或对硬件的要求: 在完成预训练的大模型上，使用几百或上千的例子进行微调训练，就可以让一个小模型在特定任务上表现良好

预训练(pre-training)
=========================

预训练(pre-training)是一种昂贵的只有大型科技公司才能负担的技术:

- 通过学习互联网上的文本预训练通用大语言模型，需要话费数千万甚至上亿美元的经费
- 需要庞大的专门工程团队，耗时数月，使用大量的数据
- 对于专业领域的大语言模型，非互联网的专业数据训练更为有效，例如布隆伯格公司使用其内部的金融文档训练的 BloombergGPT

  - 优质和独有的训练数据是大语言模型公司的护城河
  - GPU硬件和专业人才实际上有流动性，很难被垄断

语言模型选择
==============

- 模型规模: 

  - 1B(十亿)参数: 通常擅长模式匹配并具有一些基本的世界知识(对于餐厅评论的情感分析，1B参数通常已经能够满足需求)
  - 10B(1一百亿)参数: 更广泛的世界知识，并且能更好遵循指令(可以完成类似食物订购的聊天机器人) 
  - 100B+(一千亿以上)参数: 具有丰富的世界知识，知道很多有关物理、哲学、历史和科学，并且在复杂推理方面也更好(可以作为人类很好的头脑风暴伙伴)

- 开源或闭源:

  - 闭源模型:

    - 闭源模型只能通过API调用
    - 闭源模型通常很容易集成到应用程序
    - 相关费用相对较低
    - 但是存在供应商锁定的风险

  - 开源模型:

    - 开源模型让你能够完全控制模型(避免供应商放弃模型导致的风险)
    - 可以在自建设备上运行开源模型(可能降低成本)
    - 完全控制私有数据

大语言模型遵循指令的原理
============================

- 指令微调技术(instruction tuning):

为了让大语言模型能够遵循指令而不是仅仅预测下一个单词，有一种称为指令微调的技术：选取预训练的大语言模型，在问题好的答案示例上对其进行微调。

- 人类反馈强化训练(RLHF, Reinforcement Learning from Human Feedback):

RLHF技术能够进一步提高答案的质量: 有用(Helpful), 诚实(Honest), 无害(Harmless)，也称为3H (Triple H):

  - RLHF的第一步是训练一个答案质量模型(answer quality model): 让大语言模型生生成一个问题的多个答案，然后由人类专家进行打分Score(也称为反馈reward)，根据3H的符合程度更好的答案会得到更高的分数
  - 然后使用监督学习来训练一个AI模型，让它接受LLM的回复作为输入，并根据回复的质量进行评分: 调优LLM以生成更多获得高分的答案

Agent(智能体)
================

大语言模型不仅能够以文本形式答复，现在也能:

- 通过自动化触发应用程序执行动作(例如，订购披萨)
- 调用工具完成数学计算等大语言模型不擅长的工作(由于大语言基于概率，不擅长高精度计算任务)

Agent(智能体): 超越简单的触发单一任务，而是尝试选择和执行复杂的 **行动序列**

生成式AI的商业用途
=========================

- 写作助手: LLM能够重写你提供的文章片段，生成更符合商业目标的文案(但需要使用者更为仔细地检查校对)
- 市场营销的头脑风暴: 相当于面对人类现有历史上所有的营销案例的综合提炼，使用者可以通过prompt来触发LLM从人类历史上的商业营销案例中综合出合理的方案，触发营销人员更多的创造性思维
- 招聘: 快速提炼求职者评价(LLM通常善于总结文本，但仍然需要使用者仔细验证)
- 软件开发: LLM在编写某些类型代码的 **初稿** 会很有帮助，但是LLM也经常生成错误的代码，所以实际上需要开发人员不断修复LLM生成的代码。不过，LLM对开始一项开发任务还是很有帮助的

工作的任务分析
=================

- AI不能够自动化工作，但是可以自动化任务(大模型实际上需要使用者分析和拆解任务，它自身实际上是一个任务自动化工具)

  - 大多数工作都是很多任务的集合
  - 首先要对业务有深入了解，才能分析工作合理使用生成式AI
  - 只有合理拆解任务，才可能让生成式AI增强(Augmentation)任务

- 如何评估不通任务的生成式AI的潜力( ``增强`` 或 ``完全自动化`` ):

  - 技术可行性

    - 如果一个任务能够由刚毕业大学生完成(也就是不依赖行业经验以及复杂的任务解析)，那么很可能是AI能够实现的
    - 可以尝试将自己业务中常见的场景在大语言模型中执行，评估当前大语言模型的能力是否能够满足业务要求(准确度、幻觉)
    - 通过RAG, fine-tuning或其他技术来协助改进

  - 商业价值

    - 使用AI来增强(augment)或自动化(automate)特定任务的价值有多大? (节约时间?)
    - AI是否显著加快、降低成本或更一致地完成任务，是否创造了实质性价值?

AI对工作岗位的影响评估
------------------------

主要的评估思路类似 「工作的任务分析」:

- 将一个岗位的工作进行拆解分析，列出所有的工作任务，以评估AI是否能完成或加速某项工作任务: (举例)文档中撰写可能影响极大，而园艺工作目前几乎没有影响
- 对自己的工作你需要思考工作中的任务，生成式AI可能在哪里提供帮助也就意味着哪里会受到生成式AI的影响
- 一个 ``似乎有利于`` 受影响的工作者的假设: 在技术创新的大多数方式中(蒸汽机、电力、计算机)，虽然开始的时候很多公司会考虑成本节约，但最终实际上投入更多努力追求收入增长。这是因为增长没有限制，而节省是有限的。当某个任务被自动化时，你可以重新考虑企业如何创造价值的工作流程。

新的工作流和新的机会
-----------------------

- 医疗行业的技术评估工作通过生成式AI的加速，或许能够将医生资源更多更好地完成手术
- 律师行业常规的文档工作由生成式AI加速或自动化，或许有助于将人力转向更需要直接面对客户的工作
- 软件开发的提速或许能够带来更多的A/B测试，这样对改进WEB网站可能会非常有利
- 分析你的客户的工作任务，也能找到生成式AI帮助客户提升效率的任务，这样也就提高了你的服务价值

生成式AI的典型团队组成
=========================

- 软件工程师

  - 编写软件应用程序并确保其稳健运行
  - 需要投入部分精力来学习大语言模型的基础知识和prompt能力

- 机器学习工程师

  - 负责实现AI系统
  - 需要熟悉LLM/prompting, RAG 和 fine-tuning

- 产品经理(较少)

  - 负责识别和确定项目范围，确保构建的任何东西对客户有用

- :strike:`prompt工程师` (实际上是一个炒作概念，基本上很少有公司会雇佣专职prompt engineer)

以小型团队起步
------------------

- One person team:

  - 一人承担多个角色(软件工程师、机器学习工程师)

- Two person team:

  - 软件工程师 + 机器学习工程师
  - 或者是掌握了prompt技能的软件工程师 + 产品经理，甚至是其他类型的组合

跨行业的自动化潜力评估
========================

麦肯锡报告:

- 可能会受到生成式AI较大影响的行业

  - 客户运营
  - 软件工程师( 企业IT > 产品开发 )
  - 市场营销
  - 销售
  - 产品研发(R&D)

- 较少受到AI影响的行业

  - 法律行业(生成式AI的概率性错误(幻觉)对于严谨的法律行业可能是致命错误)，但是对于个人而言影响是巨大的(如果不能合理运用AI)
  - 金融
  - 制造业
  - 供应链
  - 企业内部IT

- 受到生成式AI潜在自动化影响的行业(主要是知识工作者，即主要是通过知识创造价值的工作者)

  - 教育和工作培训
  - 商业和法律专家
  - STEM专业人士
  - ...

AI伦理
=========

AI的潜在风险: 放大了人类错误的冲动

- LLM是通过互联网文本训练的，不仅反映了人类的好的品质，也包含了人类最坏的品质(偏见、仇恨和误解)
- 喧嚣的互联网实际上存在一个放大效应(越是吵闹的人留下更多的训练数据)，而沉默的大多数可能根本没有互联网的痕迹，就像民意调查，往往并不能正确预测最后的投票结果

**通过微调技术和RLHF(人类反馈强化学习)能够降低偏见**

AI影响职业:

- 如果你的职业包含了大量AI无法取代的任务，那么是可以继续从事的职业
- **AI可能不会取代你的职业，但是会AI的人会取代不会AI的人**

``需要持续学习，不管是AI技术还是以后会出现的新的技术，人类永远无法停止进步``

大多数技术革命，会带来更多的机会，因为节约成本是有限的，而增长是无限的。但是你不能固守在被新技术摧毁的位置上，而是要随着技术的潮流向前向前...

通用人工智能AGI
==================

AGI最广泛的定义: 能够完成人类能够完成的任何智力任务的AI

目前生成式AI离AGI还很远

参考
=======

- `吴恩达最新《面向每个人的生成式AI》Generative AI for Everyone <https://www.bilibili.com/video/BV11G411X7nZ/>`_
