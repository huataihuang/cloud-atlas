.. _llama-bench:

======================
llama-bench
======================

参考
=======

- `GitHub: ggml-org/llama.cpp/examples/llama-bench/README.md <https://github.com/ggml-org/llama.cpp/blob/master/examples/llama-bench/README.md>`_
- `AMD GPU support for llama.cpp via Vulkan on Raspberry Pi 5 <https://www.reddit.com/r/LocalLLaMA/comments/1gucux2/amd_gpu_support_for_llamacpp_via_vulkan_on/>`_
- `How to benchmark 'llama.cpp' builds for specific hardware? <https://www.reddit.com/r/LocalLLaMA/comments/1ga8x4i/how_to_benchmark_llamacpp_builds_for_specific/>`_
- `Performance of llama.cpp on Apple Silicon M-series #4167 <https://github.com/ggml-org/llama.cpp/discussions/4167>`_ 提供了如何对比测试的案例
