docker exec -it ollama-amd ollama run llama3.3:70b-instruct-q4_K_M \
  --set parameter num_ctx 24576 \
  --set parameter num_gpu 999 \
  --set parameter num_thread 16 \
  --set parameter temperature 0.6 \
  --set parameter top_p 0.9
